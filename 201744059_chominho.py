# -*- coding: utf-8 -*-
"""bigData_Project_Test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IfWETqXg2tOIPLZsgcKu7Q2yB5MhkbO3

# 빅데이터 - 부동산 데이터 분석 프로젝트!

---

## - 1. 데이터 분석에 필요한 데이터 크롤링

---


1. 크롤링 테스트
- 데이터를 크롤링하여 json데이터 형식으로 저장한다.
- 다음과 같이 네이버 웹 사이트를 크롤링하여 데이터를 가져올 수 있다.
"""

import requests
import json
down_url = 'https://new.land.naver.com/api/complexes/19127'
r = requests.get(down_url,data={"sameAddressGroup":"false"},headers={
    "Accept-Encoding": "gzip, deflate, br",
    "authorization":"Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6IlJFQUxFU1RBVEUiLCJpYXQiOjE2NjM5MzE0MzksImV4cCI6MTY2Mzk0MjIzOX0.QF-Frm_t9I5yFolbTtDfl-kx4EQaBa3i57syd8dt-LU",
    "Host": "new.land.naver.com",
    "Referer": "https://new.land.naver.com/complexes/22627?ms=37.513603,127.0842597,16&a=APT:ABYG:JGC&e=RETAIL",
    "sec-ch-ua":"Chromium\";v=\"104\", \" Not A;Brand\";v=\"99\", \"Google Chrome\";v=\"104",
    "Sec-Fetch-Dest": "empty",
    "sec-ch-ua-mobile": "?0",
    "sec-ch-ua-platform": "macOS",
    "Sec-Fetch-Dest": "empty",
    "Sec-Fetch-Mode": "cors",
    "Sec-Fetch-Site": "same-origin",
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36"
})
r.encoding = "utf-8-sig"
# temp에 F12 -> Network -> Preview 에 보이는 정보를 넣는다.
temp=json.loads(r.text)
print(temp["complexDetail"])

"""2. 판다스를 이용하여 json형태의 데이터를 데이터프레임으로 만들어 준다.
- 데이터 크롤링 후 CSV 파일을 만들 때 다음과 같은 구조로 코드를 구현한다.
"""

import pandas as pd

apt_data=temp["complexDetail"]
# apt_data 속 pyoengNames를 통해 면적을 구한다.
pyoeng_list=apt_data["pyoengNames"].split(", ")
# 평수에 따라 데이터들을 데이터 프레임으로 만들어 준다.
apt_data_pd=pd.DataFrame(data=apt_data,index=range(len(pyoeng_list)))
for i in range(len(pyoeng_list)):
    apt_data_pd.loc[i,"pyoengNames"]=pyoeng_list[i]
apt_data_pd

"""3. 서울시, 송파구, 송파구에 있는 동들의 고유 코드를 크롤링한다."""

import requests
import json
import pandas as pd


# 전국 시와 도의 고유 코드를 return
def get_sido_info():
    down_url = 'https://new.land.naver.com/api/regions/list?cortarNo=0000000000'
    r = requests.get(down_url,data={"sameAddressGroup":"false"},headers={
        "Accept-Encoding": "gzip, deflate, br",
        "authorization":"Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6IlJFQUxFU1RBVEUiLCJpYXQiOjE2NjM5MzE0MzksImV4cCI6MTY2Mzk0MjIzOX0.QF-Frm_t9I5yFolbTtDfl-kx4EQaBa3i57syd8dt-LU",
        "Host": "new.land.naver.com",
        "Referer": "https://new.land.naver.com/complexes/22627?ms=37.513603,127.0842597,16&a=APT:ABYG:JGC&e=RETAIL",
        "sec-ch-ua":"Chromium\";v=\"104\", \" Not A;Brand\";v=\"99\", \"Google Chrome\";v=\"104",
        "Sec-Fetch-Dest": "empty",
        "sec-ch-ua-mobile": "?0",
        "sec-ch-ua-platform": "macOS",
        "Sec-Fetch-Dest": "empty",
        "Sec-Fetch-Mode": "cors",
        "Sec-Fetch-Site": "same-origin",
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36"
    })
    r.encoding = "utf-8-sig"
    temp=json.loads(r.text)
    temp=list(pd.DataFrame(temp["regionList"])["cortarNo"])
    return temp
test_get_sido_info = get_sido_info()

# 서울시의 코드가 0이다 (1100000000)
print(test_get_sido_info[0])

# 시/군/구의 고유 코드를 return
def get_gungu_info(sido_code):
    down_url = 'https://new.land.naver.com/api/regions/list?cortarNo='+sido_code
    r = requests.get(down_url,data={"sameAddressGroup":"false"},headers={
       "Accept-Encoding": "gzip, deflate, br",
        "authorization":"Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6IlJFQUxFU1RBVEUiLCJpYXQiOjE2NjM5MzE0MzksImV4cCI6MTY2Mzk0MjIzOX0.QF-Frm_t9I5yFolbTtDfl-kx4EQaBa3i57syd8dt-LU",
        "Host": "new.land.naver.com",
        "Referer": "https://new.land.naver.com/complexes/22627?ms=37.513603,127.0842597,16&a=APT:ABYG:JGC&e=RETAIL",
        "sec-ch-ua":"Chromium\";v=\"104\", \" Not A;Brand\";v=\"99\", \"Google Chrome\";v=\"104",
        "Sec-Fetch-Dest": "empty",
        "sec-ch-ua-mobile": "?0",
        "sec-ch-ua-platform": "macOS",
        "Sec-Fetch-Dest": "empty",
        "Sec-Fetch-Mode": "cors",
        "Sec-Fetch-Site": "same-origin",
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36"
    })
    r.encoding = "utf-8-sig"
    temp=json.loads(r.text)
    temp=list(pd.DataFrame(temp['regionList'])["cortarNo"])
    return temp
test_get_gungu_info = get_gungu_info("1100000000")
print(test_get_gungu_info)

# 읍/면/동의 고유 코드를 return
def get_dong_info(gungu_code):
    down_url = 'https://new.land.naver.com/api/regions/list?cortarNo='+gungu_code
    r = requests.get(down_url,data={"sameAddressGroup":"false"},headers={
        "Accept-Encoding": "gzip, deflate, br",
        "authorization":"Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6IlJFQUxFU1RBVEUiLCJpYXQiOjE2NjM5MzE0MzksImV4cCI6MTY2Mzk0MjIzOX0.QF-Frm_t9I5yFolbTtDfl-kx4EQaBa3i57syd8dt-LU",
        "Host": "new.land.naver.com",
        "Referer": "https://new.land.naver.com/complexes/22627?ms=37.513603,127.0842597,16&a=APT:ABYG:JGC&e=RETAIL",
        "sec-ch-ua":"Chromium\";v=\"104\", \" Not A;Brand\";v=\"99\", \"Google Chrome\";v=\"104",
        "Sec-Fetch-Dest": "empty",
        "sec-ch-ua-mobile": "?0",
        "sec-ch-ua-platform": "macOS",
        "Sec-Fetch-Dest": "empty",
        "Sec-Fetch-Mode": "cors",
        "Sec-Fetch-Site": "same-origin",
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36"
    })
    r.encoding = "utf-8-sig"
    temp=json.loads(r.text)
    temp=list(pd.DataFrame(temp['regionList'])["cortarNo"])
    return temp

# 송파구의 고유 코드(1171000000)
test_get_dong_info = get_dong_info("1171000000")
print(test_get_dong_info)

# 해당 동에 포함된 아파트들의 고유코드 리스트를 크롤링한다.
def get_apt_list(dong_code):
    down_url = 'https://new.land.naver.com/api/regions/complexes?cortarNo='+dong_code+'&realEstateType=APT&order='
    r = requests.get(down_url,data={"sameAddressGroup":"false"},headers={
        "Accept-Encoding": "gzip, deflate, br",
        "authorization":"Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6IlJFQUxFU1RBVEUiLCJpYXQiOjE2NjM5MzE0MzksImV4cCI6MTY2Mzk0MjIzOX0.QF-Frm_t9I5yFolbTtDfl-kx4EQaBa3i57syd8dt-LU",
        "Host": "new.land.naver.com",
        "Referer": "https://new.land.naver.com/complexes/22627?ms=37.513603,127.0842597,16&a=APT:ABYG:JGC&e=RETAIL",
        "sec-ch-ua":"Chromium\";v=\"104\", \" Not A;Brand\";v=\"99\", \"Google Chrome\";v=\"104",
        "Sec-Fetch-Dest": "empty",
        "sec-ch-ua-mobile": "?0",
        "sec-ch-ua-platform": "macOS",
        "Sec-Fetch-Dest": "empty",
        "Sec-Fetch-Mode": "cors",
        "Sec-Fetch-Site": "same-origin",
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36"
    })
    r.encoding = "utf-8-sig"
    temp=json.loads(r.text)
    try:
        temp=list(pd.DataFrame(temp['complexList'])["complexNo"])
    except:
        temp=[]
    return temp

# 아파트 리스트 실행 테스트
sido_list=get_sido_info() 
gungu_list=get_gungu_info(sido_list[0])
dong_list=get_dong_info(gungu_list[0])
get_apt_list(dong_list[0])[0]

"""4. 3번에서 크롤링한 고유 코드들을 이용하여 아파트 정보를 json형태로 만들어 준다.

"""

# 아파트 코드를 이용해 아파트 정보를 크롤링하여 json 형태로 temp에 담는다.
def get_apt_info(apt_code):
    down_url = 'https://new.land.naver.com/api/complexes/'+apt_code+'?sameAddressGroup=false'
    r = requests.get(down_url,data={"sameAddressGroup":"false"},headers={
        "Accept-Encoding": "gzip, deflate, br",
        "authorization":"Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6IlJFQUxFU1RBVEUiLCJpYXQiOjE2NjM5MzE0MzksImV4cCI6MTY2Mzk0MjIzOX0.QF-Frm_t9I5yFolbTtDfl-kx4EQaBa3i57syd8dt-LU",
        "Host": "new.land.naver.com",
        "Referer": "https://new.land.naver.com/complexes/22627?ms=37.513603,127.0842597,16&a=APT:ABYG:JGC&e=RETAIL",
        "sec-ch-ua":"Chromium\";v=\"104\", \" Not A;Brand\";v=\"99\", \"Google Chrome\";v=\"104",
        "Sec-Fetch-Dest": "empty",
        "sec-ch-ua-mobile": "?0",
        "sec-ch-ua-platform": "macOS",
        "Sec-Fetch-Dest": "empty",
        "Sec-Fetch-Mode": "cors",
        "Sec-Fetch-Site": "same-origin",
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36"
    })
    r.encoding = "utf-8-sig"
    temp=json.loads(r.text)
    return temp

# 학군 정보 크롤링
def get_school_info(apt_code):
    down_url = 'https://new.land.naver.com/api/complexes/'+apt_code+'/schools'
    r = requests.get(down_url,headers={
        "Accept-Encoding": "gzip, deflate, br",
        "authorization":"Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6IlJFQUxFU1RBVEUiLCJpYXQiOjE2NjM5MzE0MzksImV4cCI6MTY2Mzk0MjIzOX0.QF-Frm_t9I5yFolbTtDfl-kx4EQaBa3i57syd8dt-LU",
        "Host": "new.land.naver.com",
        "Referer": "https://new.land.naver.com/complexes/22627?ms=37.513603,127.0842597,16&a=APT:ABYG:JGC&e=RETAIL",
        "sec-ch-ua":"Chromium\";v=\"104\", \" Not A;Brand\";v=\"99\", \"Google Chrome\";v=\"104",
        "Sec-Fetch-Dest": "empty",
        "sec-ch-ua-mobile": "?0",
        "sec-ch-ua-platform": "macOS",
        "Sec-Fetch-Dest": "empty",
        "Sec-Fetch-Mode": "cors",
        "Sec-Fetch-Site": "same-origin",
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36"
    })
    r.encoding = "utf-8-sig"
    temp_school=json.loads(r.text)
    return temp_school

# 가격 정보 크롤링
def apt_price(apt_code,index):
    p_num=temp["complexPyeongDetailList"][index]["pyeongNo"]
    down_url = 'https://new.land.naver.com/api/complexes/'+apt_code+'/prices?complexNo='+apt_code+'&tradeType=A1&year=5&priceChartChange=true&areaNo='+p_num+'&areaChange=true&type=table'

    r = requests.get(down_url,headers={
        "Accept-Encoding": "gzip, deflate, br",
        "authorization":"Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6IlJFQUxFU1RBVEUiLCJpYXQiOjE2NjM5MzE0MzksImV4cCI6MTY2Mzk0MjIzOX0.QF-Frm_t9I5yFolbTtDfl-kx4EQaBa3i57syd8dt-LU",
        "Host": "new.land.naver.com",
        "Referer": "https://new.land.naver.com/complexes/22627?ms=37.513603,127.0842597,16&a=APT:ABYG:JGC&e=RETAIL",
        "sec-ch-ua":"Chromium\";v=\"104\", \" Not A;Brand\";v=\"99\", \"Google Chrome\";v=\"104",
        "Sec-Fetch-Dest": "empty",
        "sec-ch-ua-mobile": "?0",
        "sec-ch-ua-platform": "macOS",
        "Sec-Fetch-Dest": "empty",
        "Sec-Fetch-Mode": "cors",
        "Sec-Fetch-Site": "same-origin",
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36"
    })
    r.encoding = "utf-8-sig"
    temp_price=json.loads(r.text)
    return temp_price
# 아파트 번호 9562에 따른 가격 정보 크롤링 테스트
print(apt_price("9562",0))
for i in range(4):
  temp_price=apt_price('9562',i)
  print(temp_price)
  try:
    print(temp_price["marketPrices"][0]["priceChangeAmount"])
  except KeyError:
    print("no data")

# 월별 가격 정보 크롤링
def apt_months_price(apt_code,index):
    p_num=temp["complexPyeongDetailList"][index]["pyeongNo"]
    down_url = 'https://new.land.naver.com/api/complexes/'+apt_code+'/prices/real?complexNo='+apt_code+'&tradeType=A1&year=5&priceChartChange=false&areaNo='+p_num+'&type=table'

    r = requests.get(down_url,headers={
        "Accept-Encoding": "gzip, deflate, br",
        "authorization":"Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6IlJFQUxFU1RBVEUiLCJpYXQiOjE2NjM5MzE0MzksImV4cCI6MTY2Mzk0MjIzOX0.QF-Frm_t9I5yFolbTtDfl-kx4EQaBa3i57syd8dt-LU",
        "Host": "new.land.naver.com",
        "Referer": "https://new.land.naver.com/complexes/22627?ms=37.513603,127.0842597,16&a=APT:ABYG:JGC&e=RETAIL",
        "sec-ch-ua":"Chromium\";v=\"104\", \" Not A;Brand\";v=\"99\", \"Google Chrome\";v=\"104",
        "Sec-Fetch-Dest": "empty",
        "sec-ch-ua-mobile": "?0",
        "sec-ch-ua-platform": "macOS",
        "Sec-Fetch-Dest": "empty",
        "Sec-Fetch-Mode": "cors",
        "Sec-Fetch-Site": "same-origin",
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36"
    })
    r.encoding = "utf-8-sig"
    temp_months_price=json.loads(r.text)
    return temp_months_price
# print(apt_months_price("22627",0))
months_price=apt_months_price("22627",0)
print(months_price)


# 월별 가격 정보 테스트(데이터 수집 실패)
try:
  print(months_price['realPriceOnMonthList'])
  for j in range(len(months_price['realPriceOnMonthList'])):
    print(months_price['realPriceOnMonthList'][j]['realPriceList'][0]['tradeMonth'])
    print(type(months_price['realPriceOnMonthList'][j]['realPriceList'][0]['tradeMonth']))
    print(months_price['realPriceOnMonthList'][j]['realPriceList'][0]['dealPrice'])
except KeyError:
  print("no data")

"""5. 아파트 정보, 학군 정보, 가격 정보, 위치 등 모든 데이터들을 데이터 프레임 형태로 만들어 저장하고 concat을 이용하여 합친 뒤 csv파일로 저장한다."""

sido_list=get_sido_info()

# 구에 해당하는 아파트들 리스트로 초기화하기
# gungu_list=get_gungu_info(sido_list("1100000000"))
gungu_list=get_gungu_info(sido_list[0])


# 동 번호 1171000000에 해당하는 동에 대한 리스트 받기, 초기화
dong_list=get_dong_info("1171000000")
dong_apt_list=[0]*len(dong_list)

for k in range(len(dong_list)):#동마다 하나씩 저장
    apt_list=get_apt_list(dong_list[k])
    apt_list_data=[0]*len(apt_list)
    for n in range(len(apt_list)):#아파트 마다 하나씩 저장
        temp=get_apt_info(apt_list[n])
        try:
            # pyoengNames 안의 데이터를 ,를 기준으로 나누어 준다.
            area_list=temp["complexDetail"]["pyoengNames"].split(", ")
            ex_flag=1
        except KeyError:   
            ex_flag=0
            temp_data=pd.DataFrame(columns=temp_data.columns)
        if ex_flag==1:
            temp_school=get_school_info(apt_list[n])
            temp_data=pd.DataFrame(index=range(len(area_list)))
            # 아파트가 가지고 있는 데이터 중 pyoengNames 안의 데이터 개수만큼 반복한다.
            for i in range(len(area_list)):
                print(temp["complexDetail"]["address"],temp["complexDetail"]["complexName"])
                # 아파트명, 면적, 법정동주소, 도로명주소, 위도, 경도, 세대수, 임대세대수, 최고층, 최저층 데이터는 모든 아파트들이 가지고 있다.(예외처리x)
                temp_data.loc[i,"아파트명"]=temp["complexDetail"]["complexName"]
                temp_data.loc[i,"면적"]=area_list[i]
                temp_data.loc[i,"법정동주소"]=temp["complexDetail"]["address"]+" "+temp["complexDetail"]["detailAddress"]
                try:
                    temp_data.loc[i,"도로명주소"]=temp["complexDetail"]["roadAddressPrefix"]+" "+temp["complexDetail"]["roadAddress"]
                except KeyError:
                    temp_data.loc[i,"도로명주소"]=temp["complexDetail"]["roadAddressPrefix"]
                temp_data.loc[i,"latitude"]=temp["complexDetail"]["latitude"]
                temp_data.loc[i,"longitude"]=temp["complexDetail"]["longitude"]
                temp_data.loc[i,"세대수"]=temp["complexDetail"]["totalHouseholdCount"]
                temp_data.loc[i,"임대세대수"]=temp["complexDetail"]["totalLeaseHouseholdCount"]
                temp_data.loc[i,"최고층"]=temp["complexDetail"]["highFloor"]
                temp_data.loc[i,"최저층"]=temp["complexDetail"]["lowFloor"]
                try:
                    temp_data.loc[i,"해당면적_세대수"]=temp["complexPyeongDetailList"][i]["householdCountByPyeong"]
                except KeyError:   
                    temp_data.loc[i,"해당면적_세대수"]=""
                try:
                    temp_data.loc[i,"현관구조"]=temp["complexPyeongDetailList"][i]["entranceType"]
                except KeyError:   
                    temp_data.loc[i,"현관구조"]=""
                
                temp_price=apt_price(apt_list[n],i)
                print(temp_price)
                try:
                    # 아파트 가격
                    temp_data.loc[i,"가격"]=temp_price["marketPrices"][0]["dealAveragePrice"]
                except KeyError:   
                    temp_data.loc[i,"가격"]=""
                try:
                    # 최근 가격 변동
                    temp_data.loc[i,"최근가격변동"]=temp_price["marketPrices"][0]["priceChangeAmount"]
                except KeyError:   
                    temp_data.loc[i,"최근가격변동"]=""

                try:
                    temp_data.loc[i,"겨울관리비"]=temp["complexPyeongDetailList"][i]["averageMaintenanceCost"]["winterTotalPrice"]
                except KeyError:   
                    temp_data.loc[i,"겨울관리비"]=""
                try:
                    temp_data.loc[i,"여름관리비"]=temp["complexPyeongDetailList"][i]["averageMaintenanceCost"]["summerTotalPrice"]
                except KeyError:   
                    temp_data.loc[i,"여름관리비"]=""
                try:
                    temp_data.loc[i,"매매호가"]=temp["complexPyeongDetailList"][i]["articleStatistics"]["dealPriceString"]
                except KeyError:   
                    temp_data.loc[i,"매매호가"]=""
                try:
                    temp_data.loc[i,"전세호가"]=temp["complexPyeongDetailList"][i]["articleStatistics"]["leasePriceString"]
                except KeyError:   
                    temp_data.loc[i,"전세호가"]=""
                try:
                    temp_data.loc[i,"월세호가"]=temp["complexPyeongDetailList"][i]["articleStatistics"]["rentPriceString"]
                except KeyError:   
                    temp_data.loc[i,"월세호가"]=""
                try:
                    temp_data.loc[i,"실거래가"]=temp["complexPyeongDetailList"][i]["articleStatistics"]["rentPriceString"]
                except KeyError:   
                    temp_data.loc[i,"실거래가"]=""
                try:
                    temp_data.loc[i,"초등학교_학군정보"]=temp_school['schools'][0]["schoolName"]
                except KeyError:   
                    temp_data.loc[i,"초등학교_학군정보"]=""
                except IndexError :   
                    temp_data.loc[i,"초등학교_학군정보"]=""
                try:
                    temp_data.loc[i,"초등학교_설립정보"]=temp_school['schools'][0]["organizationType"]
                except KeyError:   
                    temp_data.loc[i,"초등학교_설립정보"]=""
                except IndexError :   
                    temp_data.loc[i,"초등학교_설립정보"]=""
                try:
                    temp_data.loc[i,"초등학교_남학생수"]=temp_school['schools'][0]["maleStudentCount"]
                except KeyError:   
                    temp_data.loc[i,"초등학교_남학생수"]=""
                except IndexError :   
                    temp_data.loc[i,"초등학교_남학생수"]=""
                try:
                    temp_data.loc[i,"초등학교_여학생수"]=temp_school['schools'][0]["femaleStudentCount"]
                except KeyError:   
                    temp_data.loc[i,"초등학교_여학생수"]=""
                except IndexError :   
                    temp_data.loc[i,"초등학교_여학생수"]=""

            #time.sleep(1)
        apt_list_data[n]=temp_data
    if apt_list_data==[]:
        dong_apt_list[k]=pd.DataFrame(columns=temp_data.columns)
    else:
        dong_apt_list[k]=pd.concat(apt_list_data, ignore_index=True)
gungu_apt_list=pd.concat(dong_apt_list, ignore_index=True)
gungu_apt_list.to_csv(temp["complexDetail"]["roadAddressPrefix"]+".csv",encoding="CP949")

"""---

## - 2. '부동산 가격' 데이터 분석 준비하기

---

크롤링 후 결과 값으로 나온 CSV 파일의 이름을 바꿔주어야 한다. => songpa_apt.csv

##### - 폰트 깨짐현상을 막기 위해 font를 다운로드
"""

# 한글 깨짐 현상을 위한 font 다운로드(다운해도 깨짐현상이 지속)
!sudo apt-get install -y fonts-nanum
!sudo fc-cache -fv
!rm ~/.cache/matplotlib -rf

"""---

### 2-1. 데이터 전처리 후 지도에 핀으로 표시하여 시각화

#### 2-1-1. 데이터 추출
- 최근 가격 변동이 존재하는 아파트(df_test)
- 매매호가의 데이터가 존재하는 아파트(df_change_price)
- 가격의 데이터가 존재하는 아파트(df_price_nan)

- 모든 데이터 추출 완료(df_final)
"""

# Commented out IPython magic to ensure Python compatibility.
# %reset -f
import pandas as pd

# 서울시 송파구.csv파일명을 sonpa_apt로 바꾸어 작업해야 한다.
df = pd.read_csv('/content/songpa_apt.csv',encoding="CP949")

# 최근 가격 변동이 존재하는 아파트
df_test_price = df[:]
df_test = df_test_price.dropna(how='any', subset=['최근가격변동'], axis=0)
# print(df_test.head())

# 매매호가가 NaN인 데이터들 제거
df_change_price = df_test_price.dropna(how='any', subset=['매매호가'], axis=0)


# 가격이 NaN인 데이터 제거
df_price_nan = df_change_price.dropna(how='any', subset=['가격'], axis=0)

df_final = df_price_nan[:]

"""
#### 2-1-2. 데이터 시각화
- 추출이 끝난 데이터들을 지도를 통해 확인해보자."""

import pandas as pd
import folium

# 지도 만들기
smap = folium.Map(location=[37.5144533,127.1059047], tiles='Stamen Terrain', zoom_start=15)

# 아파트 이름과 가격 정보를 넣어 핀을 찍는다
for name,price , lat, lng in zip(df_final.아파트명,df_final.매매호가, df_final.latitude, df_final.longitude):
  folium.Marker([lat,lng], popup=[name,price]).add_to(smap)

smap

"""---
### 2-2. 초등학교 학군에 따른 세대수 차이가 있을까?

#### 2-2-1. 데이터 전처리

- 데이터 불러오기
"""

# Commented out IPython magic to ensure Python compatibility.
# %reset -f
import pandas as pd

df = pd.read_csv('/content/songpa_apt.csv',encoding="CP949")

"""

- 데이터 검토하기"""

# 크롤링 데이터
print(df.head())

# 데이터 행, 열 개수 출력
print(df.shape)

# 데이터 정보 출력
print(df.info())

# 데이터 요약 통계량
print(df.describe())

"""- 데이터 검토하기"""

# 초등학교 학군정보를 통한 데이터 확인

# 변수 타입
print(df['초등학교_학군정보'].dtypes)

# 학교 별 빈도 구하기
print(df['초등학교_학군정보'].value_counts())

"""#### 2-2-2. 데이터 시각화"""

import seaborn as sns
# 결측치 확인
print(df['초등학교_학군정보'].isna().sum())

# 학군 정보에 해당하는 아파트 개수 그래프
df_school = df.dropna(how='any', subset=['초등학교_학군정보'], axis=0)
sns.set(rc={'figure.figsize':(60,8)},font="NanumBarunGothic")
sns.countplot(data=df_school, x='초등학교_학군정보')

"""---

### 2-3. 초등학교 공립과 혁신 학군의 아파트 가격의 평균은 어떻게 될까?

#### 2-3-1. 데이터 전처리
"""

df_school = df.dropna(how='any', subset=['초등학교_설립정보'], axis=0)
df_school_establish_price = df_school.dropna(how='any', subset=['가격'], axis=0)


# group을 이용하여 학군으로 그루핑
grouped_school_establish_price = df_school_establish_price.groupby(['초등학교_설립정보'])

# 학군에 해당하는 아파트들의 평균 가격
grouped_school_establish_price_mean = grouped_school_establish_price.mean()
print(grouped_school_establish_price_mean["가격"])

"""#### 2-3-2. 데이터 시각화"""

import seaborn as sns
# lineplot 그래프
sns.set_style('darkgrid')
sns.set(rc={'figure.figsize':(18,8)},font="NanumBarunGothic")
sns.lineplot(data=grouped_school_establish_price_mean, x='초등학교_설립정보',y='가격', marker='o', color='r', linestyle=':')

"""---

### 2-4. 송파구에 가격이 하락하는 아파트의 비율은 어떻게 될까?

#### 2-4-1. 데이터 전처리하기
- numpy를 사용하여 다양한 데이터들을 추출한다.
- 아파트 가격이 변화한 비율을 songpa_change_rate의 열로 추가해 준다.
- 아파트 가격이 변화하지 않은 데이터들을 삭제한다.

- 최근 하락 추세, 하락하는 아파트 개수, 하락하는 아파트 비율을 확인한다.

- 하락하는 아파트들을 지도를 통해 시각적으로 확인한다.
"""

# Commented out IPython magic to ensure Python compatibility.
# %reset -f
import pandas as pd

# 서울시 송파구.csv파일명을 sonpa_apt로 바꾸어 작업해야 한다.
df = pd.read_csv('/content/songpa_apt.csv',encoding="CP949")

# 최근 가격 변동이 존재하는 아파트
df_test_price = df[:]
df_test = df_test_price.dropna(how='any', subset=['최근가격변동'], axis=0)
# print(df_test.head())

# 매매호가가 NaN인 데이터들 제거
df_change_price = df_test_price.dropna(how='any', subset=['매매호가'], axis=0)


# 가격이 NaN인 데이터 제거
df_price_nan = df_change_price.dropna(how='any', subset=['가격'], axis=0)

df_final = df_price_nan[:]

import numpy as np

# 아파트 가격이 변화한 비율을 추가(값이 워낙 작아 100을 곱해준다)
def songpa_minus_apt(a, b):
  return round((a/(a+b))*100)

df_final['songpa_change_rate'] = df_final.apply(lambda x: songpa_minus_apt(x['최근가격변동'],x['가격']), axis=1)

# 아파트 변동 가격의 비율이 0인 데이터 없애기 전처리
df_final['songpa_change_rate'].replace(0,np.nan, inplace=True)
df_final.dropna(subset=['songpa_change_rate'], axis=0, inplace=True)

# 아파트 변동 가격의 평균(- 값일 경우 대세 하락, + 값일 경우 대세 상승)
print("최근 하락 추세 : ",end="")
print(df_final['songpa_change_rate'].mean())

# 하락하는 아파트 개수
print("하락하는 아파트 개수 : ",end="")
print(df_final['songpa_change_rate'].count())

# 하락하는 아파트의 비율
print("하락하는 아파트 비율 :",end="")
print((df_final['songpa_change_rate'].count()/df_price_nan['최근가격변동'].count()))

import folium
# 송파구청을 시작 위치로 설정한다.
smap = folium.Map(location=[37.5144533,127.1059047],  zoom_start=15)

for name,rate , lat, lng in zip(df_final.아파트명,df_final.songpa_change_rate, df_final.latitude, df_final.longitude):
  folium.CircleMarker([lat,lng],
                      radius=10,
                      color='brown',
                      fill=True,
                      fill_color='coral',
                      fill_opacity=0.7,
                      popup=[name,rate]).add_to(smap)
smap

"""
#### 2-4-2. 데이터 시각화

- 가격의 변동을 matplotlib의 pie chart를 활용하여 비율비교를 하였다."""

import matplotlib.pyplot as plt


# 가격이 하락하는 아파트의 개수
price_change_minus=sum(df_price_nan.최근가격변동 < 0)
# 가격 변동이 없는 아파트의 개수
price_change_zero=sum(df_price_nan.최근가격변동 == 0)
# 가격이 상승하는 아파트의 개수
price_change_plus=sum(df_price_nan.최근가격변동 > 0)

ratio=[price_change_minus, price_change_zero, price_change_plus]
labels=['price drop', 'no price change', 'price rice']
# labels=['가격 하락', '가격변동없음', '가격 상승']
explode = [0, 0.1, 0]
colors=['lightsalmon','tomato','oldlace']
plt.pie(ratio, labels=labels,colors=colors, explode=explode, autopct='%.1f%%')

plt.show()

"""- 학군에 해당하는 아파트들의 평균 가격을 lineplot 그래프로 나타낸다."""

import seaborn as sns

# 학군에 따른 가격 분포
df_school_zone=df_price_nan[:]

# 학군이 없는 데이터들을 제거
df_school_zone = df_school_zone.dropna(how='any', subset=['최근가격변동'], axis=0)


# group을 이용하여 학군으로 그루핑
grouped_school = df_school_zone.groupby(['초등학교_학군정보'])

# 학군에 해당하는 아파트들의 평균 가격
grouped_school_price_mean = grouped_school.mean()

# lineplot 그래프
sns.set_style('darkgrid')
sns.set(rc={'figure.figsize':(70,8)},font="NanumBarunGothic")
sns.lineplot(data=grouped_school_price_mean, x='초등학교_학군정보',y='가격', marker='o', color='r', linestyle=':')